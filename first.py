# ä¾èµ–å¯¼å…¥ï¼ˆå®Œå…¨é™é»˜æˆåŠŸæç¤ºï¼Œä»…ä¿ç•™é”™è¯¯æç¤ºï¼‰
try:
    import streamlit as st
    import pandas as pd
    import numpy as np
    from sklearn.model_selection import train_test_split
    from sklearn.preprocessing import OneHotEncoder, StandardScaler
    from sklearn.compose import ColumnTransformer
    from sklearn.pipeline import Pipeline
    from sklearn.ensemble import RandomForestRegressor
    from sklearn.metrics import r2_score, mean_absolute_error
    import joblib
    import os
    import requests
    from io import StringIO
    # æ— ä»»ä½•æˆåŠŸæç¤ºè¾“å‡ºï¼ˆåˆ é™¤æ‰€æœ‰st.success/printï¼‰
except ImportError as e:
    st.error(f"âŒ ç¼ºå°‘ä¾èµ–åº“ï¼š{str(e)}")
    st.error("è¯·ç¡®ä¿requirements.txtåŒ…å«æ‰€æœ‰ä¾èµ–å¹¶é‡å¯åº”ç”¨ï¼")
    st.stop()

# é¡µé¢åŸºç¡€é…ç½®
st.set_page_config(
    page_title="åŒ»ç–—è´¹ç”¨é¢„æµ‹ç³»ç»Ÿ",
    page_icon="ğŸ¥",
    layout="wide",
    initial_sidebar_state="expanded"
)

# ---------------------- 1. åŠ è½½CSVæ–‡ä»¶ï¼ˆå®Œå…¨é™é»˜æˆåŠŸæç¤ºï¼‰ ----------------------
@st.cache_data
def load_data():
    """åŠ è½½CSVæ–‡ä»¶ï¼Œä»…åœ¨å¤±è´¥æ—¶æ˜¾ç¤ºé”™è¯¯ï¼ŒæˆåŠŸæ— ä»»ä½•æç¤º"""
    local_csv = "insurance-chinese.csv"
    github_raw_url = "https://raw.githubusercontent.com/OPGOE/yiliao/main/insurance-chinese.csv"
    encodings = ["utf-8-sig", "gbk", "utf-8", "gb2312"]

    # æœ¬åœ°è¯»å–é€»è¾‘
    if os.path.exists(local_csv):
        for enc in encodings:
            try:
                df = pd.read_csv(local_csv, encoding=enc, on_bad_lines="skip")
                df.columns = df.columns.str.strip().str.replace(" ", "")
                required_cols = ["å¹´é¾„", "æ€§åˆ«", "å­å¥³æ•°é‡", "æ˜¯å¦å¸çƒŸ", "åŒºåŸŸ", "åŒ»ç–—è´¹ç”¨"]
                if all(col in df.columns for col in required_cols):
                    X = df[["å¹´é¾„", "æ€§åˆ«", "å­å¥³æ•°é‡", "æ˜¯å¦å¸çƒŸ", "åŒºåŸŸ"]]
                    y = df["åŒ»ç–—è´¹ç”¨"]
                    return X, y, df
            except:
                continue

    # è¿œç¨‹è¯»å–é€»è¾‘ï¼ˆæ— ä»»ä½•ä¿¡æ¯æç¤ºï¼‰
    try:
        headers = {"User-Agent": "Mozilla/5.0"}
        resp = requests.get(github_raw_url, headers=headers, timeout=15)
        resp.raise_for_status()
        for enc in encodings:
            try:
                resp.encoding = enc
                df = pd.read_csv(StringIO(resp.text), on_bad_lines="skip")
                df.columns = df.columns.str.strip().str.replace(" ", "")
                required_cols = ["å¹´é¾„", "æ€§åˆ«", "å­å¥³æ•°é‡", "æ˜¯å¦å¸çƒŸ", "åŒºåŸŸ", "åŒ»ç–—è´¹ç”¨"]
                if all(col in df.columns for col in required_cols):
                    X = df[["å¹´é¾„", "æ€§åˆ«", "å­å¥³æ•°é‡", "æ˜¯å¦å¸çƒŸ", "åŒºåŸŸ"]]
                    y = df["åŒ»ç–—è´¹ç”¨"]
                    return X, y, df
            except:
                continue
        st.error("âŒ è¿œç¨‹CSVæ–‡ä»¶æ ¼å¼é”™è¯¯ï¼Œç¼ºå°‘å¿…è¦åˆ—æˆ–ç¼–ç ä¸å…¼å®¹ï¼")
        st.stop()
    except requests.exceptions.HTTPError as e:
        if e.response.status_code == 404:
            st.error(f"âŒ è¿œç¨‹CSVæ–‡ä»¶ä¸å­˜åœ¨ï¼ˆ404ï¼‰ï¼Œè¯·æ£€æŸ¥é“¾æ¥ï¼š{github_raw_url}")
        else:
            st.error(f"âŒ è¿œç¨‹è¯»å–å¤±è´¥ï¼ˆHTTP {e.response.status_code}ï¼‰")
        st.stop()
    except requests.exceptions.Timeout:
        st.error("âŒ è¿æ¥GitHubè¶…æ—¶ï¼Œè¯·æ£€æŸ¥ç½‘ç»œï¼")
        st.stop()
    except Exception as e:
        st.error(f"âŒ CSVè¯»å–å¤±è´¥ï¼š{str(e)}")
        st.stop()

# ---------------------- 2. æ¨¡å‹è®­ç»ƒï¼ˆä»…å¤±è´¥æ—¶æç¤ºï¼‰ ----------------------
def train_model(X, y):
    """è®­ç»ƒæ¨¡å‹ï¼ŒæˆåŠŸæ— æç¤ºï¼Œå¤±è´¥æ˜¾ç¤ºé”™è¯¯"""
    try:
        X_train, X_test, y_train, y_test = train_test_split(
            X, y, test_size=0.2, random_state=42
        )
        cat_features = ["æ€§åˆ«", "æ˜¯å¦å¸çƒŸ", "åŒºåŸŸ"]
        num_features = ["å¹´é¾„", "å­å¥³æ•°é‡"]

        preprocessor = ColumnTransformer(
            transformers=[
                ("num", StandardScaler(), num_features),
                ("cat", OneHotEncoder(drop="first", sparse_output=False), cat_features)
            ]
        )

        model = Pipeline([
            ("preprocessor", preprocessor),
            ("regressor", RandomForestRegressor(n_estimators=50, random_state=42))
        ])

        model.fit(X_train, y_train)
        joblib.dump(model, "model.pkl")
        y_pred = model.predict(X_test)
        return model, r2_score(y_test, y_pred), mean_absolute_error(y_test, y_pred)
    except Exception as e:
        st.error(f"âŒ æ¨¡å‹è®­ç»ƒå¤±è´¥ï¼š{str(e)}")
        st.stop()

# ---------------------- 3. åŠ è½½æ¨¡å‹ï¼ˆä»…å¤±è´¥æ—¶æç¤ºï¼‰ ----------------------
@st.cache_resource
def load_model():
    """åŠ è½½æ¨¡å‹ï¼ŒæˆåŠŸæ— æç¤ºï¼Œå¤±è´¥è‡ªåŠ¨é‡æ–°è®­ç»ƒ"""
    if os.path.exists("model.pkl"):
        try:
            return joblib.load("model.pkl")
        except:
            X, y, _ = load_data()
            model, _, _ = train_model(X, y)
            return model
    else:
        X, y, _ = load_data()
        model, _, _ = train_model(X, y)
        return model

# ---------------------- 4. é¡µé¢ä¸»é€»è¾‘ ----------------------
def main():
    # ä¾§è¾¹æ å¯¼èˆª
    st.sidebar.title("ğŸ§­ å¯¼èˆª")
    page = st.sidebar.radio(
        "",
        ["ç®€ä»‹", "é¢„æµ‹åŒ»ç–—è´¹ç”¨"],
        index=1
    )

    # ç®€ä»‹é¡µé¢
    if page == "ç®€ä»‹":
        st.title("ğŸ¥ åŒ»ç–—è´¹ç”¨é¢„æµ‹ç³»ç»Ÿ")
        st.markdown("---")
        st.markdown("""
        ## ğŸ“‹ ç³»ç»Ÿç®€ä»‹
        æœ¬ç³»ç»Ÿæ˜¯åŸºäºæœºå™¨å­¦ä¹ çš„åŒ»ç–—è´¹ç”¨é¢„æµ‹å·¥å…·ï¼Œæ—¨åœ¨ä¸ºä¿é™©å…¬å¸å’ŒåŒ»ç–—æœºæ„æä¾›å‡†ç¡®çš„è´¹ç”¨é¢„æµ‹å‚è€ƒã€‚
        
        ### ğŸ¯ ä¸»è¦åŠŸèƒ½
        - **æ™ºèƒ½é¢„æµ‹**: åŸºäºéšæœºæ£®æ—ç®—æ³•ï¼Œå‡†ç¡®é¢„æµ‹ä¸ªäººå¹´åº¦åŒ»ç–—è´¹ç”¨
        - **å¤šå› ç´ åˆ†æ**: ç»¼åˆè€ƒè™‘å¹´é¾„ã€æ€§åˆ«ã€å¸çƒŸçŠ¶å†µã€å­å¥³æ•°é‡ã€åœ°åŒºç­‰å› ç´ 
        - **é£é™©è¯„ä¼°**: è‡ªåŠ¨è¯†åˆ«é«˜é£é™©å› ç´ å¹¶æä¾›å¥åº·å»ºè®®
        - **å®æ—¶è®¡ç®—**: è¾“å…¥ä¿¡æ¯åå³æ—¶è·å¾—é¢„æµ‹ç»“æœ
        
        ### ğŸ“ ä½¿ç”¨è¯´æ˜
        1. ç‚¹å‡»å·¦ä¾§å¯¼èˆªä¸­çš„"é¢„æµ‹åŒ»ç–—è´¹ç”¨"
        2. å¡«å†™è¢«ä¿é™©äººçš„åŸºæœ¬ä¿¡æ¯
        3. ç‚¹å‡»"é¢„æµ‹åŒ»ç–—è´¹ç”¨"æŒ‰é’®
        4. æŸ¥çœ‹é¢„æµ‹ç»“æœå’Œé£é™©æç¤º
        
        ğŸ’¡ **æç¤º**: é¢„æµ‹ç»“æœä»…ä¾›å‚è€ƒï¼Œå®é™…åŒ»ç–—è´¹ç”¨å¯èƒ½å› ä¸ªäººå¥åº·çŠ¶å†µã€åŒ»ç–—æ”¿ç­–ç­‰å› ç´ è€Œæœ‰æ‰€ä¸åŒã€‚
        """)
    
    # é¢„æµ‹é¡µé¢
    else:
        st.title("ğŸ¥ åŒ»ç–—è´¹ç”¨é¢„æµ‹ç³»ç»Ÿ")
        st.markdown("---")
        st.markdown("åŸºäºå¤–éƒ¨CSVæ•°æ®çš„åŒ»ç–—è´¹ç”¨é¢„æµ‹å·¥å…·")
        st.markdown("---")
        
        # æ ¸å¿ƒåŠ è½½æ­¥éª¤ï¼ˆæ— æˆåŠŸæç¤ºï¼‰
        try:
            X, y, df = load_data()
            model = load_model()
        except Exception as e:
            st.error(f"âŒ ç³»ç»Ÿåˆå§‹åŒ–å¤±è´¥ï¼š{str(e)}")
            return

        # è¾“å…¥è¡¨å•
        st.subheader("ğŸ“ è¢«ä¿é™©äººä¿¡æ¯")
        col1, col2 = st.columns(2)
        with col1:
            age = st.number_input("å¹´é¾„", min_value=0, max_value=100, value=30, step=1)
            gender = st.radio("æ€§åˆ«", options=["ç”·æ€§", "å¥³æ€§"], horizontal=True)
            children = st.number_input("å­å¥³æ•°é‡", min_value=0, max_value=10, value=0, step=1)
        with col2:
            smoker = st.radio("æ˜¯å¦å¸çƒŸ", options=["å¦", "æ˜¯"], horizontal=True)
            region_options = df["åŒºåŸŸ"].unique().tolist() if len(df["åŒºåŸŸ"].unique()) > 0 else ["ä¸œåŒ—", "è¥¿åŒ—", "ä¸œå—", "è¥¿å—"]
            region = st.selectbox("åŒºåŸŸ", options=region_options)
            bmi = st.number_input("BMIæŒ‡æ•°", min_value=10.0, max_value=50.0, value=25.0, step=0.1)

        # é¢„æµ‹æŒ‰é’®
        st.markdown("---")
        if st.button("ğŸš€ é¢„æµ‹åŒ»ç–—è´¹ç”¨", type="primary"):
            input_data = pd.DataFrame({
                "å¹´é¾„": [age],
                "æ€§åˆ«": [gender],
                "å­å¥³æ•°é‡": [children],
                "æ˜¯å¦å¸çƒŸ": [smoker],
                "åŒºåŸŸ": [region]
            })
            try:
                prediction = model.predict(input_data)[0]
                st.success(f"ğŸ’° é¢„è®¡å¹´åº¦åŒ»ç–—è´¹ç”¨ï¼š${prediction:,.2f}")
                
                # é£é™©æç¤º
                warnings = []
                if smoker == "æ˜¯": warnings.append("å¸çƒŸä¼šæ˜¾è‘—å¢åŠ åŒ»ç–—è´¹ç”¨é£é™©")
                if bmi > 30: warnings.append("BMIè¿‡é«˜å¯èƒ½å¢åŠ å¥åº·é£é™©")
                if age > 60: warnings.append("å¹´é¾„è¾ƒå¤§ï¼ŒåŒ»ç–—è´¹ç”¨é£é™©è¾ƒé«˜")
                if warnings:
                    st.markdown("---")
                    st.subheader("âš ï¸ é£é™©æç¤º")
                    for w in warnings:
                        st.warning(w)
            except Exception as e:
                st.error(f"âŒ é¢„æµ‹å¤±è´¥ï¼š{str(e)}")

if __name__ == "__main__":
    main()
