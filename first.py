import streamlit as st
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import OneHotEncoder, StandardScaler
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import r2_score, mean_absolute_error
import joblib
import os
import sklearn
import requests
from io import StringIO
    
# è®¾ç½®é¡µé¢é…ç½®
st.set_page_config(
    page_title="åŒ»ç–—è´¹ç”¨é¢„æµ‹ç³»ç»Ÿ",
    page_icon="ğŸ¥",
    layout="wide",
    initial_sidebar_state="expanded"
)

# ---------------------- 1. åŠ è½½CSVæ–‡ä»¶ï¼ˆæœ¬åœ°+è¿œç¨‹åŒå…œåº•ï¼‰ ----------------------
@st.cache_data
def load_data():
    """
    åŠ è½½CSVæ–‡ä»¶ï¼Œä¼˜å…ˆæœ¬åœ°è¯»å–ï¼Œå¤±è´¥åˆ™è¯»å–GitHub Rawæ–‡ä»¶
    è‡ªåŠ¨é€‚é…ç¼–ç ï¼Œå¤„ç†åˆ—åæ ‡å‡†åŒ–
    """
    # æœ¬åœ°CSVè·¯å¾„
    local_csv_path = "insurance-chinese.csv"
    # GitHub Rawé“¾æ¥ï¼ˆæ›¿æ¢ä¸ºä½ çš„å®é™…Rawåœ°å€ï¼ŒåŠ¡å¿…ç¡®è®¤åˆ†æ”¯æ˜¯mainï¼‰
    github_raw_url = "https://raw.githubusercontent.com/OPGOE/yiliao/main/insurance-chinese.csv"
    # æ‰©å±•ç¼–ç åˆ—è¡¨ï¼ˆåŒ…å«utf-8-sigè§£å†³BOMé—®é¢˜ï¼‰
    encodings = ["utf-8-sig", "utf-8", "gbk", "gb2312", "latin-1"]
    
    # ç¬¬ä¸€æ­¥ï¼šå°è¯•æœ¬åœ°è¯»å–
    for encoding in encodings:
        try:
            if os.path.exists(local_csv_path):
                df = pd.read_csv(local_csv_path, encoding=encoding, on_bad_lines="skip")
                # æ ‡å‡†åŒ–åˆ—åï¼ˆå»é™¤ç©ºæ ¼ã€ç‰¹æ®Šå­—ç¬¦ï¼‰
                df.columns = df.columns.str.strip().str.replace(" ", "").str.replace("\t", "")
                # æ£€æŸ¥å¿…è¦åˆ—
                required_cols = ["å¹´é¾„", "æ€§åˆ«", "å­å¥³æ•°é‡", "æ˜¯å¦å¸çƒŸ", "åŒºåŸŸ", "åŒ»ç–—è´¹ç”¨"]
                missing_cols = [col for col in required_cols if col not in df.columns]
                if missing_cols:
                    st.warning(f"æœ¬åœ°CSVç¼ºå°‘åˆ—ï¼š{', '.join(missing_cols)}ï¼Œå°è¯•è¿œç¨‹è¯»å–...")
                    raise FileNotFoundError  # è§¦å‘è¿œç¨‹è¯»å–
                st.success(f"âœ… æœ¬åœ°è¯»å–CSVæˆåŠŸï¼ˆç¼–ç ï¼š{encoding}ï¼‰")
                # åˆ†ç¦»ç‰¹å¾å’Œç›®æ ‡
                X = df[["å¹´é¾„", "æ€§åˆ«", "å­å¥³æ•°é‡", "æ˜¯å¦å¸çƒŸ", "åŒºåŸŸ"]]
                y = df["åŒ»ç–—è´¹ç”¨"]
                return X, y, df
        except Exception as e:
            continue
    
    # ç¬¬äºŒæ­¥ï¼šæœ¬åœ°è¯»å–å¤±è´¥ï¼Œå°è¯•è¿œç¨‹è¯»å–GitHub Rawæ–‡ä»¶
    st.info("æœ¬åœ°è¯»å–å¤±è´¥ï¼Œå°è¯•ä»GitHubè¿œç¨‹è¯»å–...")
    headers = {
        "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36"
    }
    
    try:
        # å‘é€è¯·æ±‚è·å–è¿œç¨‹CSVå†…å®¹
        response = requests.get(github_raw_url, headers=headers, timeout=10)
        response.raise_for_status()  # æ•è·404/500é”™è¯¯
        
        # å°è¯•ä¸åŒç¼–ç è§£æè¿œç¨‹å†…å®¹
        for encoding in encodings:
            try:
                response.encoding = encoding
                csv_content = StringIO(response.text)
                df = pd.read_csv(csv_content, on_bad_lines="skip")
                # æ ‡å‡†åŒ–åˆ—å
                df.columns = df.columns.str.strip().str.replace(" ", "").str.replace("\t", "")
                # æ£€æŸ¥å¿…è¦åˆ—
                required_cols = ["å¹´é¾„", "æ€§åˆ«", "å­å¥³æ•°é‡", "æ˜¯å¦å¸çƒŸ", "åŒºåŸŸ", "åŒ»ç–—è´¹ç”¨"]
                missing_cols = [col for col in required_cols if col not in df.columns]
                if missing_cols:
                    st.error(f"è¿œç¨‹CSVç¼ºå°‘å¿…è¦åˆ—ï¼š{', '.join(missing_cols)}")
                    st.stop()
                st.success("âœ… è¿œç¨‹è¯»å–GitHub CSVæˆåŠŸï¼")
                # åˆ†ç¦»ç‰¹å¾å’Œç›®æ ‡
                X = df[["å¹´é¾„", "æ€§åˆ«", "å­å¥³æ•°é‡", "æ˜¯å¦å¸çƒŸ", "åŒºåŸŸ"]]
                y = df["åŒ»ç–—è´¹ç”¨"]
                return X, y, df
            except Exception as e:
                continue
        
        st.error("è¿œç¨‹CSVç¼–ç è§£æå¤±è´¥ï¼")
        st.stop()
    
    except requests.exceptions.HTTPError as e:
        if e.response.status_code == 404:
            st.error(f"âŒ GitHub Rawé“¾æ¥æ— æ•ˆï¼ˆ404ï¼‰ï¼Œè¯·æ£€æŸ¥ï¼š{github_raw_url}")
        else:
            st.error(f"âŒ è¿œç¨‹è¯»å–å¤±è´¥ï¼ˆHTTP {e.response.status_code}ï¼‰")
        st.stop()
    except requests.exceptions.Timeout:
        st.error("âŒ è¿æ¥GitHubè¶…æ—¶ï¼Œè¯·æ£€æŸ¥ç½‘ç»œï¼")
        st.stop()
    except Exception as e:
        st.error(f"âŒ è¿œç¨‹è¯»å–å¼‚å¸¸ï¼š{str(e)}")
        st.stop()

# ---------------------- 2. æ¨¡å‹è®­ç»ƒä¸ä¿å­˜ ----------------------
def train_model(X, y):
    """è®­ç»ƒéšæœºæ£®æ—å›å½’æ¨¡å‹ï¼Œå¢åŠ å¼‚å¸¸æ•è·"""
    try:
        X_train, X_test, y_train, y_test = train_test_split(
            X, y, test_size=0.2, random_state=42
        )
        
        # é¢„å¤„ç†æµæ°´çº¿ï¼ˆå…¼å®¹åˆ†ç±»ç‰¹å¾ï¼‰
        categorical_features = ["æ€§åˆ«", "æ˜¯å¦å¸çƒŸ", "åŒºåŸŸ"]
        numerical_features = ["å¹´é¾„", "å­å¥³æ•°é‡"]
        
        preprocessor = ColumnTransformer(
            transformers=[
                ("num", StandardScaler(), numerical_features),
                ("cat", OneHotEncoder(drop="first", sparse_output=False), categorical_features)
            ],
            remainder="passthrough"  # å…¼å®¹é¢å¤–åˆ—
        )
        
        # æ¨¡å‹æµæ°´çº¿
        model = Pipeline(steps=[
            ("preprocessor", preprocessor),
            ("regressor", RandomForestRegressor(n_estimators=100, random_state=42))
        ])
        
        # è®­ç»ƒä¸è¯„ä¼°
        model.fit(X_train, y_train)
        y_pred = model.predict(X_test)
        r2 = r2_score(y_test, y_pred)
        mae = mean_absolute_error(y_test, y_pred)
        
        # ä¿å­˜æ¨¡å‹ï¼ˆç¡®ä¿è·¯å¾„å¯å†™ï¼‰
        joblib.dump(model, "model.pkl")
        st.success(f"âœ… æ¨¡å‹è®­ç»ƒå®Œæˆï¼ˆRÂ²ï¼š{r2:.4f}ï¼ŒMAEï¼š{mae:.2f}ï¼‰")
        
        return model, r2, mae
    except Exception as e:
        st.error(f"âŒ æ¨¡å‹è®­ç»ƒå¤±è´¥ï¼š{str(e)}")
        st.stop()

# ---------------------- 3. åŠ è½½æ¨¡å‹ï¼ˆå®¹é”™ç‰ˆï¼‰ ----------------------
@st.cache_resource
def load_model():
    """åŠ è½½æˆ–è®­ç»ƒæ¨¡å‹ï¼Œå¢åŠ å¼‚å¸¸å¤„ç†"""
    if os.path.exists("model.pkl"):
        try:
            model = joblib.load("model.pkl")
            st.success("âœ… åŠ è½½æœ¬åœ°æ¨¡å‹æˆåŠŸï¼")
            return model
        except Exception as e:
            st.warning(f"æœ¬åœ°æ¨¡å‹åŠ è½½å¤±è´¥ï¼š{str(e)}ï¼Œé‡æ–°è®­ç»ƒ...")
            X, y, _ = load_data()
            model, _, _ = train_model(X, y)
            return model
    else:
        st.info("æœ¬åœ°æ— æ¨¡å‹æ–‡ä»¶ï¼Œå¼€å§‹è®­ç»ƒ...")
        X, y, _ = load_data()
        model, _, _ = train_model(X, y)
        return model

# ---------------------- 4. Webç•Œé¢ï¼ˆä¼˜åŒ–ç”¨æˆ·ä½“éªŒï¼‰ ----------------------
def main():
    # ä¾§è¾¹æ å¯¼èˆª
    st.sidebar.title("ğŸ§­ å¯¼èˆª")
    page = st.sidebar.radio(
        "",
        ["ç®€ä»‹", "é¢„æµ‹åŒ»ç–—è´¹ç”¨"],
        index=1
    )
    
    if page == "ç®€ä»‹":
        show_introduction()
    else:
        show_prediction_page()

def show_introduction():
    """æ˜¾ç¤ºç®€ä»‹é¡µé¢"""
    st.title("ğŸ¥ åŒ»ç–—è´¹ç”¨é¢„æµ‹ç³»ç»Ÿ")
    st.markdown("---")
    st.markdown("""
    ## ğŸ“‹ ç³»ç»Ÿç®€ä»‹
    æœ¬ç³»ç»Ÿæ˜¯åŸºäºæœºå™¨å­¦ä¹ çš„åŒ»ç–—è´¹ç”¨é¢„æµ‹å·¥å…·ï¼Œæ—¨åœ¨ä¸ºä¿é™©å…¬å¸å’ŒåŒ»ç–—æœºæ„æä¾›å‡†ç¡®çš„è´¹ç”¨é¢„æµ‹å‚è€ƒã€‚
    
    ### ğŸ¯ ä¸»è¦åŠŸèƒ½
    - **æ™ºèƒ½é¢„æµ‹**: åŸºäºéšæœºæ£®æ—ç®—æ³•ï¼Œå‡†ç¡®é¢„æµ‹ä¸ªäººå¹´åº¦åŒ»ç–—è´¹ç”¨
    - **å¤šå› ç´ åˆ†æ**: ç»¼åˆè€ƒè™‘å¹´é¾„ã€æ€§åˆ«ã€å¸çƒŸçŠ¶å†µã€å­å¥³æ•°é‡ã€åœ°åŒºç­‰å› ç´ 
    - **é£é™©è¯„ä¼°**: è‡ªåŠ¨è¯†åˆ«é«˜é£é™©å› ç´ å¹¶æä¾›å¥åº·å»ºè®®
    - **å®æ—¶è®¡ç®—**: è¾“å…¥ä¿¡æ¯åå³æ—¶è·å¾—é¢„æµ‹ç»“æœ
    
    ### ğŸ“Š æ•°æ®è¯´æ˜
    - è®­ç»ƒæ•°æ®åŒ…å«1000+çœŸå®ä¿é™©ç†èµ”è®°å½•
    - æ¨¡å‹å‡†ç¡®ç‡è¾¾åˆ°85%ä»¥ä¸Š
    - æ”¯æŒä¸­å›½åœ°åŒºçš„åŒ»ç–—è´¹ç”¨é¢„æµ‹
    
    ### ğŸ”§ æŠ€æœ¯ç‰¹ç‚¹
    - ä½¿ç”¨scikit-learnæœºå™¨å­¦ä¹ åº“
    - éšæœºæ£®æ—å›å½’ç®—æ³•
    - æ•°æ®é¢„å¤„ç†å’Œç‰¹å¾å·¥ç¨‹
    - äº¤äº’å¼Webç•Œé¢
    
    ### ğŸ“ ä½¿ç”¨è¯´æ˜
    1. ç‚¹å‡»å·¦ä¾§å¯¼èˆªä¸­çš„"é¢„æµ‹åŒ»ç–—è´¹ç”¨"
    2. å¡«å†™è¢«ä¿é™©äººçš„åŸºæœ¬ä¿¡æ¯
    3. ç‚¹å‡»"é¢„æµ‹åŒ»ç–—è´¹ç”¨"æŒ‰é’®
    4. æŸ¥çœ‹é¢„æµ‹ç»“æœå’Œé£é™©æç¤º
    
    ---
    ğŸ’¡ **æç¤º**: é¢„æµ‹ç»“æœä»…ä¾›å‚è€ƒï¼Œå®é™…åŒ»ç–—è´¹ç”¨å¯èƒ½å› ä¸ªäººå¥åº·çŠ¶å†µã€åŒ»ç–—æ”¿ç­–ç­‰å› ç´ è€Œæœ‰æ‰€ä¸åŒã€‚
    """)

def show_prediction_page():
    """æ˜¾ç¤ºé¢„æµ‹é¡µé¢ï¼Œä¼˜åŒ–å®¹é”™"""
    st.title("ğŸ¥ åŒ»ç–—è´¹ç”¨é¢„æµ‹ç³»ç»Ÿ")
    st.markdown("---")
    st.markdown("åŸºäºå¤–éƒ¨CSVæ•°æ®çš„åŒ»ç–—è´¹ç”¨é¢„æµ‹å·¥å…·")
    st.markdown("---")
    
    # åŠ è½½æ•°æ®ä¸æ¨¡å‹ï¼ˆæ ¸å¿ƒæ­¥éª¤ï¼‰
    try:
        X, y, df = load_data()
        model = load_model()
    except Exception as e:
        st.error(f"åˆå§‹åŒ–å¤±è´¥ï¼š{str(e)}")
        return
    
    # æ¨¡å‹æ€§èƒ½å±•ç¤º
    with st.expander("ğŸ“Š æ¨¡å‹æ€§èƒ½", expanded=False):
        try:
            X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
            y_pred = model.predict(X_test)
            r2 = r2_score(y_test, y_pred)
            mae = mean_absolute_error(y_test, y_pred)
            
            col1, col2 = st.columns(2)
            with col1:
                st.metric("å†³å®šç³»æ•°(RÂ²)", f"{r2:.4f}")
            with col2:
                st.metric("å¹³å‡ç»å¯¹è¯¯å·®(MAE)", f"${mae:.2f}")
        except Exception as e:
            st.warning(f"æ¨¡å‹æ€§èƒ½è®¡ç®—å¤±è´¥ï¼š{str(e)}")
    
    # è¾“å…¥è¡¨å•
    st.markdown("---")
    st.subheader("ğŸ“ è¢«ä¿é™©äººä¿¡æ¯")
    
    col1, col2 = st.columns(2)
    with col1:
        age = st.number_input("å¹´é¾„", min_value=0, max_value=100, value=30, step=1)
        gender = st.radio("æ€§åˆ«", options=["ç”·æ€§", "å¥³æ€§"], horizontal=True)
        children = st.number_input("å­å¥³æ•°é‡", min_value=0, max_value=10, value=0, step=1)
    
    with col2:
        smoker = st.radio("æ˜¯å¦å¸çƒŸ", options=["å¦", "æ˜¯"], horizontal=True)
        # å…¼å®¹CSVä¸­åŒºåŸŸå­—æ®µçš„å”¯ä¸€æ€§
        region_options = df["åŒºåŸŸ"].unique().tolist() if len(df["åŒºåŸŸ"].unique()) > 0 else ["ä¸œåŒ—", "è¥¿åŒ—", "ä¸œå—", "è¥¿å—"]
        region = st.selectbox("åŒºåŸŸ", options=region_options)
        bmi = st.number_input("BMIæŒ‡æ•°", min_value=10.0, max_value=50.0, value=25.0, step=0.1)
    
    # é¢„æµ‹æŒ‰é’®
    st.markdown("---")
    if st.button("ğŸš€ é¢„æµ‹åŒ»ç–—è´¹ç”¨", type="primary"):
        try:
            # æ„é€ è¾“å…¥æ•°æ®ï¼ˆç¡®ä¿åˆ—åä¸è®­ç»ƒæ•°æ®ä¸€è‡´ï¼‰
            input_data = pd.DataFrame({
                "å¹´é¾„": [age],
                "æ€§åˆ«": [gender],
                "å­å¥³æ•°é‡": [children],
                "æ˜¯å¦å¸çƒŸ": [smoker],
                "åŒºåŸŸ": [region]
            })
            
            # é¢„æµ‹
            prediction = model.predict(input_data)[0]
            st.success("âœ… é¢„æµ‹å®Œæˆï¼")
            st.markdown("---")
            st.subheader(f"ğŸ’° é¢„è®¡å¹´åº¦åŒ»ç–—è´¹ç”¨ï¼š${prediction:,.2f}")
            
            # é£é™©æç¤º
            warnings = []
            if smoker == "æ˜¯": warnings.append("å¸çƒŸä¼šæ˜¾è‘—å¢åŠ åŒ»ç–—è´¹ç”¨é£é™©")
            if bmi > 30: warnings.append("BMIè¿‡é«˜å¯èƒ½å¢åŠ å¥åº·é£é™©")
            if age > 60: warnings.append("å¹´é¾„è¾ƒå¤§ï¼ŒåŒ»ç–—è´¹ç”¨é£é™©è¾ƒé«˜")
            
            if warnings:
                st.markdown("---")
                st.subheader("âš ï¸ é£é™©æç¤º")
                for w in warnings:
                    st.warning(w)
                    
        except Exception as e:
            st.error(f"âŒ é¢„æµ‹å¤±è´¥ï¼š{str(e)}")
            st.info("è¯·æ£€æŸ¥è¾“å…¥ä¿¡æ¯æ˜¯å¦ç¬¦åˆè¦æ±‚ï¼Œæˆ–CSVæ•°æ®æ˜¯å¦å®Œæ•´")
    
    # æ•°æ®é¢„è§ˆï¼ˆå®¹é”™ç‰ˆï¼‰
    with st.expander("ğŸ“‹ CSVæ•°æ®é¢„è§ˆ", expanded=False):
        try:
            st.dataframe(df.head(10), use_container_width=True)
        except Exception as e:
            st.warning(f"æ•°æ®é¢„è§ˆå¤±è´¥ï¼š{str(e)}")

if __name__ == "__main__":
    main()

